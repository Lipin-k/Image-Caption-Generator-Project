# Image-Caption-Generator-Project

This project focuses on generating descriptive captions for images using a deep learning approach. It leverages a Convolutional Neural Network (CNN), VGG16 for image feature extraction and a Sequence-to-Sequence (Seq2Seq) model, incorporating LSTM layers, to generate natural language descriptions.The dataset consists of 8k images and 5 captions for each image. The project involves preprocessing textual data, splitting the dataset for training and testing, building the model, and generating captions for test images. Additionally, the results are visualized, and the model is tested with real-world images to evaluate its performance using BLEU Score.


Dataset Link: https://www.kaggle.com/adityajn105/flickr8k

Libraries Used:

1) Numpy
2) Pandas
3) Tensorflow
4) Keras
5) OpenCV
6) Matplotlib
   
